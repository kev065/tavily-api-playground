{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVdtcEDEW9hU"
   },
   "source": [
    "# Notebook App for Data Enrichment Using LangGrpah and Tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd-1RKEnW9hV"
   },
   "source": [
    "## Introduction\n",
    "Welcome to the Data Enrichment Sheet!\n",
    "\n",
    "This sheet is designed to enhance your data by populating missing values using advanced search capabilities from Tavily and the LangGraph Framework. It accepts either a CSV or Excel file path or a Google Sheet name (follow the instructions in the \"Google Colab Set Up\" section).\n",
    "\n",
    "For Google Sheets and Excel files, the agent will create an additional sheet containing the populated data table. For CSV files, a new CSV file will be generated with the enriched data provided by the agent.\n",
    "\n",
    "For detailed instructions on how to use this sheet and call the agent to start enriching your data, please refer to the \"Call Agent\" section below.\n",
    "\n",
    "Note: The results generated by the DataEnrichmentAgent are not perfect and could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caex2CjJW9hW"
   },
   "source": [
    "## Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFRvBW_uapc2",
    "outputId": "5d86347c-12ee-4062-992b-50b94e3b44f4"
   },
   "outputs": [],
   "source": [
    "!pip install langgraph tavily-python openai openpyxl python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fb5brO4BW9hW"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "luqDjbJNW9hW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import asyncio\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from typing import TypedDict, Annotated\n",
    "from openai import AsyncOpenAI\n",
    "from tavily import AsyncTavilyClient\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y47hwJmg21I"
   },
   "source": [
    "## Google Colab Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxH73q2Gz1Rd"
   },
   "source": [
    "To connent with Google Sheets upload this notebook to Google Colab. Uncomment the following lines and ensure to input your Google Sheet name for your agent in the Call Agent section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nh7mcADKhAdu"
   },
   "outputs": [],
   "source": [
    "# import gspread # Python API for Google Sheets\n",
    "# from google.colab import auth\n",
    "# from google.auth import default\n",
    "\n",
    "# # Authenticate and create the gspread client\n",
    "# auth.authenticate_user()\n",
    "# creds, _ = default()\n",
    "\n",
    "# gc = gspread.authorize(creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1a8tvFOW9hX"
   },
   "source": [
    "## Build Master Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHcXyoX6Y2dz"
   },
   "source": [
    "### Master's Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Vzxz1mKhYzZN"
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "  raw_data: pd.DataFrame                  # original panda data frame\n",
    "  new_data: pd.DataFrame                  # populated panda data frame\n",
    "  colab: str                              # google sheet name\n",
    "  excel: str                              # path to Excel file\n",
    "  csv: str                                # path to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUJuVVjV70y9"
   },
   "source": [
    "### Master's Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j7uYJ337Ymgw"
   },
   "outputs": [],
   "source": [
    "class DataEnrichmentAgent():\n",
    "  def __init__(self):\n",
    "    # Initialize agents\n",
    "    data_agent = DataAgent()\n",
    "    enrich_agent = EnrichAgent()\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node(\"get_data\", data_agent.get_df)\n",
    "    workflow.add_node(\"enrich_data\", enrich_agent.run)\n",
    "    workflow.add_node(\"write_data\", data_agent.write_df)\n",
    "\n",
    "    workflow.set_entry_point(\"get_data\")\n",
    "\n",
    "    workflow.add_edge(\"get_data\", \"enrich_data\")\n",
    "    workflow.add_edge(\"enrich_data\", \"write_data\")\n",
    "    workflow.add_edge(\"write_data\", END)\n",
    "\n",
    "    self.workflow = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4HoV9Ds8RmL"
   },
   "source": [
    "## Sub Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SBektD48VjA"
   },
   "source": [
    "### Data Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAgent():\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  \n",
    "  # Convert columns with numeric values to appropriate types\n",
    "  def convert_numeric_columns(self, df):\n",
    "      for col in df.columns:\n",
    "          # Check if column contains numeric values\n",
    "          if pd.api.types.is_numeric_dtype(df[col]):\n",
    "              # Attempt to convert to integers if possible\n",
    "              try:\n",
    "                  df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "              except ValueError:\n",
    "                  # If conversion to Int64 fails, keep as float\n",
    "                  df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "      return df\n",
    "\n",
    "  # Google Sheets Integration through Colab\n",
    "  def connect_to_google_sheets_colab(self, sheet_name):\n",
    "    sheet = gc.open(sheet_name).sheet1\n",
    "    data = sheet.get_all_records()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    return df\n",
    "\n",
    "  def get_df(self, state: AgentState):\n",
    "    # Function to get Data Frame and store in state\n",
    "    if state.get('colab'):\n",
    "        df = self.connect_to_google_sheets_colab(state['colab'])\n",
    "        df = self.convert_numeric_columns(df)\n",
    "        df = df.astype(str)  # Ensure all values are strings\n",
    "        return {\"raw_data\": df}\n",
    "    elif state.get('csv'):\n",
    "        df = pd.read_csv(state['csv'])\n",
    "        return {\"raw_data\": df}\n",
    "    elif state.get('excel'):\n",
    "        df = pd.read_excel(state['excel'])\n",
    "        return {\"raw_data\": df}\n",
    "    else:\n",
    "        print(\"Either colab or csv or excel argument is required.\")\n",
    "        return\n",
    "\n",
    "  def write_df(self, state: AgentState):\n",
    "    try:\n",
    "      df = state['new_data']\n",
    "      if state['colab']:\n",
    "          # Use existing Colab authentication (assuming `gc` is a gspread client)\n",
    "          spreadsheet = gc.open(state['colab'])\n",
    "\n",
    "          # Add a new sheet\n",
    "          sheet_name = f\"AgentSheet{len(spreadsheet.worksheets()) + 1}\"\n",
    "          spreadsheet.add_worksheet(title=sheet_name, rows=str(df.shape[0]), cols=str(df.shape[1]))\n",
    "          new_sheet = spreadsheet.worksheet(sheet_name)\n",
    "\n",
    "          # Write DataFrame to the new sheet\n",
    "          new_sheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "          print(f\"Data written to new sheet '{sheet_name}' in Google Sheets document '{state['colab']}'.\")\n",
    "\n",
    "      elif state['excel']:\n",
    "        # Load the existing workbook\n",
    "        wb = load_workbook(state['excel'])\n",
    "\n",
    "        # Generate a new sheet name based on existing sheets count\n",
    "        sheet_name = f\"AgentSheet{len(wb.sheetnames) + 1}\"\n",
    "\n",
    "        # Create a new sheet and write data\n",
    "        ws = wb.create_sheet(title=sheet_name)\n",
    "\n",
    "        # Write DataFrame to the new sheet\n",
    "        for r in dataframe_to_rows(df, index=False, header=True):\n",
    "          ws.append(r)\n",
    "\n",
    "        # Save changes to the Excel file\n",
    "        wb.save(state['excel'])\n",
    "        wb.close()\n",
    "        print(f\"Data written to new sheet '{sheet_name}' in Excel document '{state['excel']}'.\")\n",
    "\n",
    "      elif state['csv']:\n",
    "        # Extract file name from the csv path and construct new name\n",
    "        file_name = os.path.basename(state['csv'])\n",
    "        # Output DataFrame to a CSV file\n",
    "        output_csv = f\"AgentSheet{file_name}\" # construct new file path\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Data written to CSV file '{output_csv}'.\")\n",
    "      \n",
    "      else:\n",
    "        print(\"No valid file type specified.\")\n",
    "    except Exception as e:\n",
    "      print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_lNj1cFFvZF"
   },
   "source": [
    "### Enrich Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "T5EeOw18bj4J"
   },
   "outputs": [],
   "source": [
    "# Colors\n",
    "RED = '\\033[91m'\n",
    "GREEN = '\\033[92m'\n",
    "BLUE = '\\033[94m'\n",
    "YELLOW = '\\033[93m'\n",
    "ENDC = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnrichAgent():\n",
    "  def __init__(self):\n",
    "    # Maximum number of columns to try to resolve at once\n",
    "    self.MAX_COLS_PER_PASS = 5\n",
    "\n",
    "    # Maximum number of fill-in passes to attempt\n",
    "    self.MAX_PASSES = 5\n",
    "\n",
    "    self.model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "  \n",
    "  def is_missing_value(self, value):\n",
    "        \"\"\"\n",
    "        Check if a value is considered missing. Handles various representations of missing values.\n",
    "        \"\"\"\n",
    "        if pd.isna(value) or value == '' or str(value).lower() == 'nan':\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "  async def generate_search_query(self, head, columns):\n",
    "    \"\"\"\n",
    "    This function takes the head of the table (all column names) and the names of the columns that it needs to fill in, and generates a search prompt for Tavily\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a researcher with the task of filling in a spreadsheet. The spreadsheet contains the columns {str(head)} and {str(columns)} have not been filled in yet.\n",
    "    Write a web search query for a search engine that you will use to fill in each row of the spreadsheet one by one. In the query, replace the name of the entry you are researching with $ENTRY\n",
    "    Respond only with the query.\"\"\"\n",
    "\n",
    "    messages = [SystemMessage(content=prompt)]\n",
    "    response = await self.model.ainvoke(messages)\n",
    "\n",
    "    return response.content.strip('\\'\"')\n",
    "\n",
    "  async def fill_in_row(self, df, head, row_index, columns, search_query):\n",
    "    \"\"\"\n",
    "    This function takes a data frame, a row to complete, a list of column names to complete and the query to search.\n",
    "    It calls the Tavily API to retrieve information using the search_query and prompts OpenAI to extract column values from the response\n",
    "    \"\"\"\n",
    "    # if the search_query is a coroutine, await it\n",
    "    if asyncio.iscoroutine(search_query):\n",
    "        search_query = await search_query\n",
    "\n",
    "    entry = str(df.iloc[row_index][head[0]])\n",
    "\n",
    "    search_query = search_query.replace(\"$ENTRY\", entry)\n",
    "    try:\n",
    "        print(f\"{BLUE}Tavily Search: {search_query}{ENDC}\")\n",
    "        tavily_response = await tavily.search(search_query)\n",
    "        # Only save the title and content from each Tavily result\n",
    "        research_results = [{'title': r['title'], 'content': r['content']} for r in tavily_response['results']]\n",
    "    except Exception as e:\n",
    "        print(f\"{RED}Error during Tavily search: {str(e)}{ENDC}\")\n",
    "        return\n",
    "\n",
    "    # To ensure consistency with the existing data, come up with an example based on existing data in the df\n",
    "    example = {}\n",
    "    for col in columns:\n",
    "      for i in range(len(df)):\n",
    "        if i != row_index and not self.is_missing_value(df.iloc[i][col]):\n",
    "          example[col] = df.iloc[i][col]\n",
    "          break\n",
    "\n",
    "    example_str = f'Example: {str(example)}\\n' if len(example) > 0 else ''\n",
    "\n",
    "    prompt = f\"You are filling in a spreadsheet using online sources. The following fields need to be filled in for the entry '{entry}': {', '.join(columns)}\\n\" \\\n",
    "              \"Using the data below, find values for as many of these fields as you can. Reply with a JSON object, linking each field to its value.\\n\" \\\n",
    "            f\"{example_str}\" \\\n",
    "              \"Values must be written in a spreadsheet friendly format. If the data is not sufficient to complete a field, simply omit it from the result object.\\n\" \\\n",
    "              \"Do not incude any text other than the JSON object in your response.\\n\\n\" \\\n",
    "                      f\"{str(research_results)}\"\n",
    "\n",
    "    json_model = self.model.bind(response_format={\"type\": \"json_object\"})\n",
    "    messages = [SystemMessage(content=prompt)]\n",
    "    response = await json_model.ainvoke(messages)\n",
    "\n",
    "    json_str = response.content\n",
    "    try:\n",
    "      fields = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "      print(f\"{RED}Failed to parse JSON: {json_str}{ENDC}\")\n",
    "      return\n",
    "\n",
    "    for field, value in fields.items():\n",
    "      if field not in columns:\n",
    "        print(f\"{RED}LLM returned an invalid field '{field}'{ENDC}\")\n",
    "        continue\n",
    "\n",
    "      col_index = df.columns.get_loc(field)\n",
    "      if not self.is_missing_value(df.iloc[row_index][field]):\n",
    "        print(f\"{YELLOW}Skipping field '{field}' as it already has a value:{ENDC}\", df.iloc[row_index][field])\n",
    "        continue\n",
    "\n",
    "      df.at[row_index, field] = str(value)\n",
    "      print(f\"{GREEN}Filled in field '{field}' with value '{value}'{ENDC}\")\n",
    "\n",
    "  async def run(self, state: AgentState):\n",
    "    \"\"\"\n",
    "    Main Function:\n",
    "    First, we try to fill in the maximum number of column in one pass for each row. We then loop and try to fill in the missing columns\n",
    "    \"\"\"\n",
    "    df = state['raw_data'].copy()\n",
    "    head = list(df.columns)\n",
    "    # First pass: try to fill in as much as possible\n",
    "    #general_query = await self.generate_search_query(head, head[1:self.MAX_COLS_PER_PASS+1])\n",
    "    general_query = await self.generate_search_query(head, head[1:])\n",
    "\n",
    "    coroutines = []\n",
    "    for row_index in range(len(df)):\n",
    "      has_missing_columns = False\n",
    "      for col_index in range(len(head)):\n",
    "        if self.is_missing_value(df.iloc[row_index][head[col_index]]):\n",
    "          has_missing_columns = True\n",
    "          break\n",
    "\n",
    "\n",
    "      if not has_missing_columns:\n",
    "        print(f\"{YELLOW}No missing columns for row {row_index}{ENDC}\")\n",
    "        continue\n",
    "\n",
    "      coroutines.append(self.fill_in_row(df, head, row_index, head[1:], general_query))\n",
    "\n",
    "    await asyncio.gather(*coroutines)\n",
    "\n",
    "    # Now, fill in the missing fields for each row\n",
    "    for _ in range(self.MAX_PASSES):\n",
    "      all_completed = True\n",
    "\n",
    "      coroutines = []\n",
    "      for row_index in range(len(df)):\n",
    "        missing_columns = []\n",
    "        for col_index in range(len(head)):\n",
    "          if self.is_missing_value(df.iloc[row_index][head[col_index]]) and len(missing_columns) < self.MAX_COLS_PER_PASS:\n",
    "            missing_columns.append(head[col_index])\n",
    "\n",
    "        if len(missing_columns) > 0:\n",
    "          all_completed = False\n",
    "          print(f\"Missing columns for row {row_index}: {', '.join(missing_columns)}\")\n",
    "          query = self.generate_search_query(head, missing_columns)\n",
    "          coroutines.append(self.fill_in_row(df, head, row_index, missing_columns, query))\n",
    "        else:\n",
    "          print(f\"No missing columns for row {row_index}\")\n",
    "\n",
    "      if all_completed:\n",
    "        break\n",
    "\n",
    "      await asyncio.gather(*coroutines)\n",
    "\n",
    "    # Check if everything was completed\n",
    "    all_completed = True\n",
    "    for row_index in range(len(df)):\n",
    "      for col_index in range(len(head)):\n",
    "        if self.is_missing_value(df.iloc[row_index][head[col_index]]):\n",
    "          all_completed = False\n",
    "          break\n",
    "\n",
    "    if all_completed:\n",
    "      print(f\"{GREEN}All rows completed{ENDC}\")\n",
    "    else:\n",
    "      print(f\"{RED}Not all rows completed{ENDC}\")\n",
    "    return {\"new_data\": df}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbFQs7Mxw8S8"
   },
   "source": [
    "# Call Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y84CPSSY5R7v"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set Your API Keys\n",
    "# OPENAI_API_KEY = \"YOUR OPENAI API KEY\"\n",
    "# TAVILY_API_KEY = \"YOUR TAIVLY API KEY\"\n",
    "\n",
    "# Or use .env file \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "tavily = AsyncTavilyClient(TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-yEEPnCm0p_I"
   },
   "outputs": [],
   "source": [
    "# Define the input data for your agent, specifying the path to either a CSV file or an Excel file,\n",
    "# and optionally the name of your Google Sheet\n",
    "# csv_path = \"your_csv_path\"       #E.g \"Desktop/my_csv.scv\"\n",
    "excel_path = \"data.xlsx\"         #E.g This is am example Excel file that could be found in this repoo\n",
    "# colab = \"google_sheet_name\"      #E.g \"My_Google_Sheet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "kmOGMPynhQy4",
    "outputId": "eefa3c8b-08ef-444e-b1c0-64e55d538f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTavily Search: Movie Fast and Furious details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n",
      "\u001b[94mTavily Search: Movie Despicable Me details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n",
      "\u001b[94mTavily Search: Movie Titanic details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n",
      "\u001b[94mTavily Search: Movie Avatar details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n",
      "\u001b[94mTavily Search: Movie The Godfather details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n",
      "\u001b[94mTavily Search: Movie Skyfall details including Genre, Release date, Director, Length, Composer, Has sequel\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19911/2389177379.py:91: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Romantic/Disaster' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, field] = str(value)\n",
      "/tmp/ipykernel_19911/2389177379.py:91: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1997' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, field] = str(value)\n",
      "/tmp/ipykernel_19911/2389177379.py:91: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'James Cameron' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, field] = str(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mFilled in field 'Genre' with value 'Romantic/Disaster'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value '1997'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'James Cameron'\u001b[0m\n",
      "\u001b[92mFilled in field 'Has sequel' with value 'No'\u001b[0m\n",
      "\u001b[92mFilled in field 'Genre' with value 'Action'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value 'June 11, 2001'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'Rob Cohen'\u001b[0m\n",
      "\u001b[92mFilled in field 'Has sequel' with value 'Yes'\u001b[0m\n",
      "\u001b[92mFilled in field 'Genre' with value 'Action-Adventure, Fantasy, Science Fiction'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value 'December 18, 2009'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'James Cameron'\u001b[0m\n",
      "\u001b[92mFilled in field 'Length' with value '3 Hours'\u001b[0m\n",
      "\u001b[93mSkipping field 'Has sequel' as it already has a value:\u001b[0m Yes\n",
      "\u001b[92mFilled in field 'Genre' with value 'Gangster, Epic'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value 'March 15, 1972'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'Francis Ford Coppola'\u001b[0m\n",
      "\u001b[92mFilled in field 'Has sequel' with value 'Yes'\u001b[0m\n",
      "\u001b[92mFilled in field 'Genre' with value 'Animation, Adventure, Comedy, Crime, Family, Sci-Fi'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value 'Jul 9, 2010'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'Chris Renaud, Pierre Coffin'\u001b[0m\n",
      "\u001b[92mFilled in field 'Length' with value '1 h 35 m'\u001b[0m\n",
      "\u001b[92mFilled in field 'Has sequel' with value 'Yes'\u001b[0m\n",
      "\u001b[92mFilled in field 'Genre' with value 'Action Thriller, Spy Film'\u001b[0m\n",
      "\u001b[92mFilled in field 'Release date' with value 'October 26, 2012'\u001b[0m\n",
      "\u001b[92mFilled in field 'Director' with value 'Sam Mendes'\u001b[0m\n",
      "\u001b[92mFilled in field 'Length' with value '143 min'\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'Thomas Newman'\u001b[0m\n",
      "\u001b[92mFilled in field 'Has sequel' with value 'Yes'\u001b[0m\n",
      "Missing columns for row 0: Composer\n",
      "Missing columns for row 1: Composer\n",
      "Missing columns for row 2: Length, Composer\n",
      "Missing columns for row 3: Composer\n",
      "Missing columns for row 4: Length, Composer\n",
      "No missing columns for row 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19911/2389177379.py:91: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Thomas Newman' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[row_index, field] = str(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTavily Search: Length and Composer of Titanic movie\u001b[0m\n",
      "\u001b[94mTavily Search: Movie Avatar composer\u001b[0m\n",
      "\u001b[94mTavily Search: Who composed the soundtrack for Despicable Me movie?\u001b[0m\n",
      "\u001b[94mTavily Search: Who composed the soundtrack for Fast and Furious movie?\u001b[0m\n",
      "\u001b[94mTavily Search: Length and Composer of The Godfather movie\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'James Horner'\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'Heitor Pereira, Pharrell Williams'\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'Brian Tyler'\u001b[0m\n",
      "\u001b[92mFilled in field 'Length' with value '2 Hours 55 Minutes'\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'Nino Rota'\u001b[0m\n",
      "\u001b[92mFilled in field 'Composer' with value 'James Horner'\u001b[0m\n",
      "No missing columns for row 0\n",
      "No missing columns for row 1\n",
      "Missing columns for row 2: Length\n",
      "No missing columns for row 3\n",
      "No missing columns for row 4\n",
      "No missing columns for row 5\n",
      "\u001b[94mTavily Search: Length of Titanic movie\u001b[0m\n",
      "\u001b[92mFilled in field 'Length' with value '3 Hours 15 Minutes'\u001b[0m\n",
      "No missing columns for row 0\n",
      "No missing columns for row 1\n",
      "No missing columns for row 2\n",
      "No missing columns for row 3\n",
      "No missing columns for row 4\n",
      "No missing columns for row 5\n",
      "\u001b[92mAll rows completed\u001b[0m\n",
      "Error occurred: 'colab'\n"
     ]
    }
   ],
   "source": [
    "my_agent = DataEnrichmentAgent()\n",
    "input = {\n",
    "    # Example: Uncomment and specify the path to your CSV file above\n",
    "    # \"csv\": csv_path,\n",
    "\n",
    "    # Example: Uncomment and specify the path to your Excel file above\n",
    "    \"excel\": excel_path,\n",
    "\n",
    "    # Example: Uncomment and specify your Google Sheet name above\n",
    "    # \"colab\": colab\n",
    "}\n",
    "result = await my_agent.workflow.ainvoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8q8ma2sHihs"
   },
   "source": [
    "#### Your original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "W-29kkqNHbIS",
    "outputId": "3a08a2b4-3ce6-4570-b390-8b7971193dbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Director</th>\n",
       "      <th>Length</th>\n",
       "      <th>Composer</th>\n",
       "      <th>Has sequel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fast and Furious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 Hours 20 Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despicable Me</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skyfall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Movie name  Genre  Release date  Director              Length  \\\n",
       "0  Fast and Furious    NaN           NaN       NaN  2 Hours 20 Minutes   \n",
       "1     Despicable Me    NaN           NaN       NaN                 NaN   \n",
       "2           Titanic    NaN           NaN       NaN                 NaN   \n",
       "3            Avatar    NaN           NaN       NaN                 NaN   \n",
       "4     The Godfather    NaN           NaN       NaN                 NaN   \n",
       "5           Skyfall    NaN           NaN       NaN                 NaN   \n",
       "\n",
       "   Composer Has sequel  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        Yes  \n",
       "4       NaN        NaN  \n",
       "5       NaN        NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['raw_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGBOjt-8HqUp"
   },
   "source": [
    "#### Enriched Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Director</th>\n",
       "      <th>Length</th>\n",
       "      <th>Composer</th>\n",
       "      <th>Has sequel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fast and Furious</td>\n",
       "      <td>Action</td>\n",
       "      <td>June 11, 2001</td>\n",
       "      <td>Rob Cohen</td>\n",
       "      <td>2 Hours 20 Minutes</td>\n",
       "      <td>Brian Tyler</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despicable Me</td>\n",
       "      <td>Animation, Adventure, Comedy, Crime, Family, S...</td>\n",
       "      <td>Jul 9, 2010</td>\n",
       "      <td>Chris Renaud, Pierre Coffin</td>\n",
       "      <td>1 h 35 m</td>\n",
       "      <td>Heitor Pereira, Pharrell Williams</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>Romantic/Disaster</td>\n",
       "      <td>1997</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>3 Hours 15 Minutes</td>\n",
       "      <td>James Horner</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action-Adventure, Fantasy, Science Fiction</td>\n",
       "      <td>December 18, 2009</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>3 Hours</td>\n",
       "      <td>James Horner</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Gangster, Epic</td>\n",
       "      <td>March 15, 1972</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "      <td>2 Hours 55 Minutes</td>\n",
       "      <td>Nino Rota</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skyfall</td>\n",
       "      <td>Action Thriller, Spy Film</td>\n",
       "      <td>October 26, 2012</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>143 min</td>\n",
       "      <td>Thomas Newman</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Movie name                                              Genre  \\\n",
       "0  Fast and Furious                                             Action   \n",
       "1     Despicable Me  Animation, Adventure, Comedy, Crime, Family, S...   \n",
       "2           Titanic                                  Romantic/Disaster   \n",
       "3            Avatar         Action-Adventure, Fantasy, Science Fiction   \n",
       "4     The Godfather                                     Gangster, Epic   \n",
       "5           Skyfall                          Action Thriller, Spy Film   \n",
       "\n",
       "        Release date                     Director              Length  \\\n",
       "0      June 11, 2001                    Rob Cohen  2 Hours 20 Minutes   \n",
       "1        Jul 9, 2010  Chris Renaud, Pierre Coffin            1 h 35 m   \n",
       "2               1997                James Cameron  3 Hours 15 Minutes   \n",
       "3  December 18, 2009                James Cameron             3 Hours   \n",
       "4     March 15, 1972         Francis Ford Coppola  2 Hours 55 Minutes   \n",
       "5   October 26, 2012                   Sam Mendes             143 min   \n",
       "\n",
       "                            Composer Has sequel  \n",
       "0                        Brian Tyler        Yes  \n",
       "1  Heitor Pereira, Pharrell Williams        Yes  \n",
       "2                       James Horner         No  \n",
       "3                       James Horner        Yes  \n",
       "4                          Nino Rota        Yes  \n",
       "5                      Thomas Newman        Yes  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['new_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['new_data'].to_excel('new_data.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "colab": {
   "collapsed_sections": [
    "v1a8tvFOW9hX",
    "XUJuVVjV70y9",
    "2SBektD48VjA"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
